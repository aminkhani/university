\documentclass[oneside, 11pt, a4paper]{book}

\usepackage[DIV=12, BCOR=1mm, headinclude=true, footinclude=false]{typearea}
\usepackage{graphicx}
\usepackage{fancyhdr}
    \pagestyle{fancy}
    \fancyhf{}
    \fancyhead[L]{\footnotesize \selectfont مریم رضوانی - امین خانی}
    \fancyhead[R]{\footnotesize \selectfont Neural Networks and Learning Machines}
    \fancyfoot[L]{\footnotesize \selectfont استاد: ابراهیم پور}
    \fancyfoot[C]{\thepage}
    \fancyfoot[R]{\footnotesize \selectfont ترجمه کتاب}
    \renewcommand{\footrulewidth}{0.4pt}
\usepackage{xcolor}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
    pdfpagemode=FullScreen,
}
\usepackage{xepersian}
    \settextfont{XB Niloofar}


\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\newlength{\saveparindent}
\AtBeginDocument{\setlength{\saveparindent}{\parindent}}
\newcommand{\indentpar}{\par\hspace*{\saveparindent}\ignorespaces}

\setcounter{chapter}{11}

\begin{document}

\begin{center}
    \mbox{}\\[2.0cm]
    \textsc{\Huge Neural Networks and Learning Machines}\\[2.5cm]
    \HRule\\[0.4cm]
    {\large \bf {\selectfont ترجمه فصل ۱۲ - برنامه نویسی پویا}}\\[0.2cm]
    \HRule\\[1.5cm]
\end{center}

\begin{flushright}
    \textbf{\selectfont نویسنده:}
\end{flushright}

\begin{center}
    \begin{minipage}{0.5\textwidth}
        \begin{flushright}
            \indentpar امین خانی \\
            \indentpar مریم رضوانی
        \end{flushright}
    \end{minipage}%
    \begin{minipage}{0.5\textwidth}
        \begin{flushleft}
            \indentpar \href{mailto:aminkhani@std.kashanu.ac.ir}{\texttt{aminkhani@std.kashanu.ac.ir}} \\
            \indentpar \href{mailto:mrymrzvni@gmail.com}{\texttt{mrymrzvni@gmail.com}}
        \end{flushleft}
    \end{minipage}
\end{center}


\vspace{\fill}
\begin{minipage}[b]{\textwidth}
    \centering
    \large
    فروردین 1402
    \vspace{30mm}
\end{minipage}%

\thispagestyle{empty}

\setcounter{page}{0}

\newpage
\tableofcontents
\newpage

\chapter{
    \LARGE{
    برنامه نویسی پویا
    \lr{Dynamic Programming -}
    }
}

\section*{مرور کلی}

\paragraph{سه هدف این فصل: \\}

\begin{enumerate}
    \item برای بحث در مورد توسعه برنامه نویسی پویا به عنوان مبنای ریاضی برنامه ریزی یک دوره عمل چند مرحله ای توسط عاملی که در یک محیط تصادفی کار می کند.
    \item برای بیان یک اشتقاق مستقیم از یادگیری تقویتی بعنوان یک شکل تقریبی از برنامه نویسی پویا.
    \item ارائه روش های غیر مستقیم برنامه نویسی پویا تقریبی برای مقابله با نفرین ابعاد.
\end{enumerate}

\paragraph{این فصل بصورت زیر طبقه بندی شده است:}

\begin{enumerate}
    \item بخش \ref{sec:1} ، بخش مقدماتی، برانگیختن انگیزه مطالعه برنامه نویسی پویا است، بحث دررابطه با فرایندهای تصمیم گیری مارکوف که در بخش \ref{sec:2} انجام شده است.
    \item بخش \ref{sec:3} از طریق \ref{sec:5} مطرح کردن نظریه برنامه نویسی پویا بلمن و دو روش مرتبط: تکرار سیاست و تکرار ارزش.
    \item بخش \ref{sec:6} منطق پشت تقریب مبتنی بر یادگیری مستقیم را توصیف می کند.برنامه نویسی پویا بدان وسیله منجربه توسعه یادگیری تفاوت های زمانی و یادگیری Q می شود.
    \item بخش \ref{sec:9} منطق پشت تقریب مبتنی بر یادگیری غیرمستقیم را توصیف می کند. برنامه نویسی پویا برای مقابله با مشکل نفرین ابعاد. بدان وسیله منجر به بررسی ارزیابی سیاست حداقل مربعات و بازگویی ارزش تقریبی ارئه شده به ترتیب دربخش \ref{sec:10} و \ref{sec:11} ارائه شده است.
\end{enumerate}
این فصل با خلاصه و بحث در بخش \ref{sec:12} به پایان می رسد.

\section{مقدمه}\label{sec:1}

در فصل مقدماتی، ما دو الگوی اصلی یادگیری را شناسایی کرده ایم. یادگیری همراه با معلم و یادگیری بدون معلم. الگوی یادگیری بدون معلم به یادگیری خود سازمان یافته (بدون نظارت) و یادگیری تقویتی تقسیم می شود.
اشکال مختلف یادگیری با معلم، یا یادگیری تحت نظارت، در فصل های 1 تا 6 و اشکال مختلف یادگیری بدون نظارت در فصل های 9 تا 11 مورد بحث قرار گرفت. یادگیری نیمه نظارتی در فصل 7 مورد بحث قرار گرفت.
در این فصل، یادگیری تقویتی را مورد بحث قرار می دهیم.

یادگیری تحت نظارت یک مشکل یادگیری «شناختی» است که تحت نظارت یک معلم انجام می شود. این متکی به در دسترس بودن مجموعه ای کافی از نمونه های ورودی-خروجی است که نماینده محیط عملیاتی هستند. در مقابل، یادگیری تقویتی یک مشکل یادگیری «رفتاری» است. این از طریق تعامل بین یک عامل و محیط آن انجام می شود، که در آن عامل یا تصمیم گیرنده به دنبال دستیابی به یک هدف خاص علیرغم وجود عدم قطعیت است (بارتو و همکاران، 1983؛ ساتون و بارتو، 1998). این واقعیت که این تعامل بدون معلم انجام می‌شود، یادگیری تقویتی را به ویژه برای موقعیت‌های پویا جذاب می‌کند، جایی که جمع‌آوری مجموعه‌ای رضایت‌بخش از نمونه‌های خروجی ورودی پرهزینه یا دشوار (اگر نه غیرممکن) است.

\paragraph{دو رویکرد برای مطالعه یادگیری تقویتی وجود دارد که به طور خلاصه به شرح زیر است:}

\begin{enumerate}
    \item رویکرد کلاسیک، که در آن یادگیری از طریق فرآیند تنبیه و پاداش، با هدف دستیابی به یک رفتار بسیار ماهرانه صورت می‌گیرد.
    \item رویکرد مدرن، که بر پایه یک تکنیک ریاضی معروف به برنامه‌نویسی پویا استوار است تا با در نظر گرفتن مراحل احتمالی آینده بدون تجربه واقعی، در مورد یک دوره عمل تصمیم بگیرد. در اینجا تاکید بر برنامه ریزی است.
\end{enumerate}

بحث ما بر یادگیری تقویتی مدرن متمرکز است. برنامه نویسی پویا تکنیکی است که به موقعیت هایی می پردازد که در آن تصمیمات به صورت مرحله ای گرفته می شوند و نتیجه هر تصمیم قبل از اتخاذ تصمیم بعدی تا حدی قابل پیش بینی است. یکی از جنبه‌های کلیدی چنین موقعیت‌هایی این است که نمی‌توان تصمیم‌ها را به تنهایی اتخاذ کرد. در عوض، میل به هزینه کم در حال حاضر باید در برابر نامطلوب بودن هزینه بالا در آینده متعادل شود. این یک مشکل تخصیص اعتبار است، زیرا اعتبار یا سرزنش باید به هر یک از مجموعه ای از تصمیمات متقابل اختصاص داده شود. برای برنامه‌ریزی بهینه، لازم است که بین هزینه‌های فوری و آتی یک معاوضه کارآمد وجود داشته باشد. چنین مبادله ای در واقع با فرمالیسم برنامه نویسی پویا تسخیر شده است. به طور خاص، برنامه نویسی پویا به مشکل اساسی زیر می پردازد:\\\indent\emph{\color{blue}
چگونه یک عامل یا تصمیم گیرنده می تواند عملکرد بلندمدت خود را در یک محیط تصادفی بهبود بخشد، در حالی که دستیابی به این بهبود ممکن است نیاز به قربانی کردن عملکرد کوتاه مدت داشته باشد؟
}\\برنامه نویسی پویا بلمن راه حلی بهینه برای این مشکل اساسی به شیوه ای ظریف و اصولی ارائه می دهد.


در هنر مدل سازی ریاضی، چالش ایجاد تعادل مناسب بین دو نهاد است، یکی عملی و دیگری نظری. به ترتیب، این دو نهاد هستند
\begin{itemize}
    \item توصیف واقع بینانه یک مسئله داده شده و
    \item قدرت روش های تحلیلی و محاسباتی برای اعمال مشکل.
\end{itemize}
در برنامه نویسی پویا، موضوع مورد توجه ویژه تصمیم گیری توسط عاملی است که در یک محیط تصادفی عمل می کند. برای پرداختن به این موضوع، مدل خود را حول فرآیندهای تصمیم مارکوف می سازیم. با توجه به وضعیت اولیه یک سیستم پویا، یک فرآیند تصمیم گیری مارکوف مبنای ریاضی را برای انتخاب دنباله ای از تصمیمات فراهم می کند که بازده از یک فرآیند تصمیم گیری مرحله N را به حداکثر می رساند. آنچه که ما توضیح دادیم ماهیت برنامه نویسی پویا بلمن است. بنابراین مناسب است که مطالعه برنامه نویسی پویا را با بحث در مورد فرآیندهای تصمیم مارکوف آغاز کنیم.



\section{فرآیند تصمیم گیری مارکوف}\label{sec:2}

عامل یا تصمیم گیرنده ای را در نظر بگیرید که با محیط خود به روشی که در شکل 12.1 نشان داده شده است در تعامل است. عامل مطابق با یک فرآیند تصمیم گیری مارکویی زمان محدود عمل می کند که به شرح زیر مشخص می شود:
\begin{itemize}
    \item محیط به صورت احتمالی تکامل می‌یابد و مجموعه‌ای محدود از حالات گسسته را اشغال می‌کند. با این حال، ایالت حاوی آمارهای گذشته نیست، حتی اگر این آمارها می تواند برای عامل مفید باشد.
    \item برای هر مرحله محیطی، مجموعه محدودی از اقدامات احتمالی وجود دارد که ممکن است توسط عامل انجام شود.
    \item هر بار که نماینده اقدامی انجام می دهد، هزینه خاصی متحمل می شود.
    \item ایالت ها مشاهده می شوند، اقداماتی انجام می شود و هزینه ها در زمان های مجزا متحمل می شوند.
\end{itemize}
\indent{در چارچوب بحث حاضر، تعریف زیر را معرفی می کنیم:}\\
\indent\emph{\color{blue}وضعیت محیط خلاصه ای از کل تجربه گذشته یک عامل است که از تعامل آن با محیط به دست می آید، به طوری که اطلاعات لازم برای عامل برای پیش بینی رفتار آینده محیط در آن خلاصه موجود است.}\\
حالت در مرحله زمانی $n$ با متغیر تصادفی $X_n$ و وضعیت واقعی در مرحله زمانی $n$ با $i_n$ نشان داده می شود. مجموعه حالت های محدود با $x$ نشان داده می شود. یکی از جنبه های شگفت انگیز برنامه نویسی پویا این است که کاربرد آن به ماهیت وضعیت بسیار کمی بستگی دارد. بنابراین ممکن است بدون هیچ گونه فرضی در مورد ساختار فضای حالت پیش برویم. همچنین توجه داشته باشید که پیچیدگی الگوریتم پویا-برنامه ریزی در بعد فضای حالت درجه دوم و در بعد فضای عمل خطی است.


برای مثال، برای حالت $i$، مجموعه اقدامات موجود (یعنی ورودی‌های اعمال شده توسط عامل به محیط) با نشان داده می‌شود، که در آن زیرنویس دوم $k$ در عمل $a_{ik}$ که توسط عامل انجام می‌شود، صرفاً در دسترس بودن بیش از یک عمل ممکن را نشان می‌دهد. زمانی که محیط در حالت $i$ است. انتقال محیط از حالت $i$ به حالت جدید j به عنوان مثال به دلیل عمل $a_{ik}$ ماهیت احتمالی دارد. اما مهمتر از همه، احتمال انتقال از حالت $i$ به حالت $j$ کاملاً به وضعیت فعلی $i$ و عملکرد مربوطه $a_{ik}$ بستگی دارد. این ویژگی مارکوف است که در فصل 11 مورد بحث قرار گرفت. این ویژگی بسیار مهم است زیرا به این معنی است که جریان فعلی وضعیت محیط اطلاعات لازم را برای عامل فراهم می کند تا تصمیم بگیرد چه اقدامی انجام دهد.


متغیر تصادفی که بیانگر عمل انجام شده توسط عامل در مرحله n زمان است با $A_n$ نشان داده می شود. اجازه دهید $p_{ij}(a)$ احتمال انتقال از حالت $i$ به حالت $j$ را نشان دهد
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.5\textwidth]{f01.png}
    \caption{بلوک دیاگرام یک عامل در تعامل با محیط خود.}
\end{figure}

اقدام انجام شده در مرحله زمانی $n$، جایی که $A_n = a$. به موجب فرض مارکف در مورد پویایی حالت، ما داریم
\begin{equation}
    p_{ij}(a) = P(X_{n+1} = j|X_n = i, A_n = a)
\end{equation}






\section{معیار بهینه بودن معادله بلمن}\label{sec:3}

متن تست

\section{تکرار سیاست}\label{sec:4}

\section{تکرار ارزش}\label{sec:5}

\section{برنامه نویسی دینامیک تقریبی: روش های مستقیم}\label{sec:6}

\section{یادگیری تفاوت زمانی}\label{sec:7}

\section{Q-یادگیری}\label{sec:8}

\section{برنامه نویسی دینامیک تقریبی: روش های غیر مستقیم}\label{sec:9}

\section{ارزیابی سیاست حداقل مربعات}\label{sec:10}

\section{تکرار سیاست تقریبی}\label{sec:11}

\section{خلاصه و بحث}\label{sec:12}


\end{document}